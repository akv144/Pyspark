{"cells":[{"cell_type":"markdown","source":["PySpark Basic Examples\nSpark Session"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"43f3110a-ad96-48b1-835d-a67e8746b5fb"}}},{"cell_type":"code","source":["spark"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"d95691af-4463-4e14-88e1-da115f6c10bb"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"\n            <div>\n                <p><b>SparkSession - hive</b></p>\n                \n        <div>\n            <p><b>SparkContext</b></p>\n\n            <p><a href=\"/?o=2995350661662673#setting/sparkui/0810-052605-a0tqpgr6/driver-7861804494066112606\">Spark UI</a></p>\n\n            <dl>\n              <dt>Version</dt>\n                <dd><code>v3.2.1</code></dd>\n              <dt>Master</dt>\n                <dd><code>local[8]</code></dd>\n              <dt>AppName</dt>\n                <dd><code>Databricks Shell</code></dd>\n            </dl>\n        </div>\n        \n            </div>\n        ","textData":null,"removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"htmlSandbox","arguments":{}}},"output_type":"display_data","data":{"text/html":["\n            <div>\n                <p><b>SparkSession - hive</b></p>\n                \n        <div>\n            <p><b>SparkContext</b></p>\n\n            <p><a href=\"/?o=2995350661662673#setting/sparkui/0810-052605-a0tqpgr6/driver-7861804494066112606\">Spark UI</a></p>\n\n            <dl>\n              <dt>Version</dt>\n                <dd><code>v3.2.1</code></dd>\n              <dt>Master</dt>\n                <dd><code>local[8]</code></dd>\n              <dt>AppName</dt>\n                <dd><code>Databricks Shell</code></dd>\n            </dl>\n        </div>\n        \n            </div>\n        "]}}],"execution_count":0},{"cell_type":"code","source":["# How to create SparkSession\n\nfrom pyspark.sql import SparkSession\nspark=SparkSession.builder.appName(\"example\").master(\"local[1]\").getOrCreate()\nspark\n"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"6104a25a-ad22-4308-84d2-061961377589"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"\n            <div>\n                <p><b>SparkSession - hive</b></p>\n                \n        <div>\n            <p><b>SparkContext</b></p>\n\n            <p><a href=\"/?o=2995350661662673#setting/sparkui/0810-052605-a0tqpgr6/driver-7861804494066112606\">Spark UI</a></p>\n\n            <dl>\n              <dt>Version</dt>\n                <dd><code>v3.2.1</code></dd>\n              <dt>Master</dt>\n                <dd><code>local[8]</code></dd>\n              <dt>AppName</dt>\n                <dd><code>Databricks Shell</code></dd>\n            </dl>\n        </div>\n        \n            </div>\n        ","textData":null,"removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"htmlSandbox","arguments":{}}},"output_type":"display_data","data":{"text/html":["\n            <div>\n                <p><b>SparkSession - hive</b></p>\n                \n        <div>\n            <p><b>SparkContext</b></p>\n\n            <p><a href=\"/?o=2995350661662673#setting/sparkui/0810-052605-a0tqpgr6/driver-7861804494066112606\">Spark UI</a></p>\n\n            <dl>\n              <dt>Version</dt>\n                <dd><code>v3.2.1</code></dd>\n              <dt>Master</dt>\n                <dd><code>local[8]</code></dd>\n              <dt>AppName</dt>\n                <dd><code>Databricks Shell</code></dd>\n            </dl>\n        </div>\n        \n            </div>\n        "]}}],"execution_count":0},{"cell_type":"code","source":["spark2=SparkSession.newSession\nspark2\n"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"77a1cade-3073-45e5-ad59-ec0734ea29e9"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"Out[8]: <function pyspark.sql.session.SparkSession.newSession(self)>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"ansi","arguments":{}}},"output_type":"display_data","data":{"text/plain":["Out[8]: <function pyspark.sql.session.SparkSession.newSession(self)>"]}}],"execution_count":0},{"cell_type":"markdown","source":["# Using PySpark Configs\n\nspark.conf.set(\"spark.executor.memory\", \"5g\")\n\n# Get a Spark Config\npartions = spark.conf.get(\"spark.sql.shuffle.partitions\")\nprint(partions)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"7b95d184-aa5d-419d-9c49-c68f364af9cc"}}},{"cell_type":"code","source":["partions = spark.conf.get(\"spark.sql.shuffle.partitions\")\nprint(partions)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"c8ee5809-6640-43d5-9345-1eaab09c7e02"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"200\n","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"ansi","arguments":{}}},"output_type":"display_data","data":{"text/plain":["200\n"]}}],"execution_count":0},{"cell_type":"code","source":["# Create PySpark DataFrame\ndf = spark.createDataFrame(\n    [(\"Scala\", 25000), (\"Spark\", 35000), (\"PHP\", 21000)],[\"Language\",\"Price\"])\ndf.show()\n"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"2ac98ba7-3ed8-4b06-b937-5eb24dd5295c"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"+--------+-----+\n|Language|Price|\n+--------+-----+\n|   Scala|25000|\n|   Spark|35000|\n|     PHP|21000|\n+--------+-----+\n\n","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"ansi","arguments":{}}},"output_type":"display_data","data":{"text/plain":["+--------+-----+\n|Language|Price|\n+--------+-----+\n|   Scala|25000|\n|   Spark|35000|\n|     PHP|21000|\n+--------+-----+\n\n"]}}],"execution_count":0},{"cell_type":"code","source":["#Working with Spark SQL\ndf.createOrReplaceTempView(\"sample_table\")\ndf2 = spark.sql(\"SELECT * FROM sample_table\")\ndf2.show()"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"6c49aee3-9e83-49e3-9377-343a1f912754"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"+--------+-----+\n|Language|Price|\n+--------+-----+\n|   Scala|25000|\n|   Spark|35000|\n|     PHP|21000|\n+--------+-----+\n\n","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"ansi","arguments":{}}},"output_type":"display_data","data":{"text/plain":["+--------+-----+\n|Language|Price|\n+--------+-----+\n|   Scala|25000|\n|   Spark|35000|\n|     PHP|21000|\n+--------+-----+\n\n"]}}],"execution_count":0},{"cell_type":"code","source":["# # Create Hive table & query it.  \n\n\n\n# spark.table(\"sample_table\").write.saveAsTable(\"sample_hive_table\")\n# df3 = spark.sql(\"SELECT * FROM sample_hive_table\")\n# df3.show()\n"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"d052a03b-a3d3-4889-9cfa-1421a9b18ea6"}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["\n# Get metadata from the Catalog\ndb=spark.catalog.listDatabases()\ndb"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"cfc8a56d-1933-49e3-ba5c-93d6558b20c8"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"Out[18]: [Database(name='default', description='Default Hive database', locationUri='dbfs:/user/hive/warehouse')]","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"ansi","arguments":{}}},"output_type":"display_data","data":{"text/plain":["Out[18]: [Database(name='default', description='Default Hive database', locationUri='dbfs:/user/hive/warehouse')]"]}}],"execution_count":0},{"cell_type":"code","source":["tbls = spark.catalog.listTables()\nprint(tbls)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"97980ddc-9604-4f48-abdf-67f6671cf966"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"[Table(name='sample_table', database=None, description=None, tableType='TEMPORARY', isTemporary=True)]\n","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"ansi","arguments":{}}},"output_type":"display_data","data":{"text/plain":["[Table(name='sample_table', database=None, description=None, tableType='TEMPORARY', isTemporary=True)]\n"]}}],"execution_count":0},{"cell_type":"code","source":["8. SparkSession Commonly Used Methods\nversion() – Returns the Spark version where your application is running, probably the Spark version your cluster is configured with.\n\ncreateDataFrame() – This creates a DataFrame from a collection and an RDD\n\ngetActiveSession() – returns an active Spark session.\n\nread() – Returns an instance of DataFrameReader class, this is used to read records from csv, parquet, avro, and more file formats into DataFrame.\n\nreadStream() – Returns an instance of DataStreamReader class, this is used to read streaming data. that can be used to read streaming data into DataFrame.\n\nsparkContext() – Returns a SparkContext.\n\nsql() – Returns a DataFrame after executing the SQL mentioned.\n\nsqlContext() – Returns SQLContext.\n\nstop() – Stop the current SparkContext.\n\ntable() – Returns a DataFrame of a table or view.\n\nudf() – Creates a PySpark UDF to use it on DataFrame, Dataset, and SQL."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"f5e663dc-3d68-4f68-a6ec-3d7a21cb3565"}},"outputs":[],"execution_count":0}],"metadata":{"application/vnd.databricks.v1+notebook":{"notebookName":"Alma(spark)","dashboards":[],"notebookMetadata":{"pythonIndentUnit":4},"language":"python","widgets":{},"notebookOrigID":1071541317021683}},"nbformat":4,"nbformat_minor":0}
